{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26a2aa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import hashlib, yaml, pandas as pd, json, re\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.schema import Document\n",
    "import fitz  # PyMuPDF for TOC + page spans\n",
    "\n",
    "DATA_DIR = Path(\"X:/ML Projects/News RAG/data/pdfs\")\n",
    "META_YAML = Path(\"./books_meta.yaml\")\n",
    "ARTIFACTS = Path(\"./artifacts\"); ARTIFACTS.mkdir(exist_ok=True)\n",
    "\n",
    "def doc_id_for(path: Path)->str:\n",
    "    h = hashlib.sha256()\n",
    "    with open(path,'rb') as f:\n",
    "        for chunk in iter(lambda: f.read(1<<20), b\"\"): h.update(chunk)\n",
    "    return h.hexdigest()[:16]\n",
    "\n",
    "# load user-supplied metadata (title/author/publisher/…)\n",
    "def load_meta_yaml(path: Path)->pd.DataFrame:\n",
    "    if not path.exists(): return pd.DataFrame()\n",
    "    data = yaml.safe_load(path.read_text(encoding=\"utf-8\"))\n",
    "    df = pd.DataFrame(data)\n",
    "    # must include at least one of filename or doc_id to match\n",
    "    return df\n",
    "\n",
    "meta_df = load_meta_yaml(META_YAML)\n",
    "\n",
    "def enrich_meta(basic: dict)->dict:\n",
    "    \"\"\"merge loader metadata with your YAML row (by filename or doc_id).\"\"\"\n",
    "    row = None\n",
    "    if not meta_df.empty:\n",
    "        fname = Path(basic[\"source\"]).name\n",
    "        m = meta_df[(meta_df.get(\"filename\",\"\")==fname) | (meta_df.get(\"doc_id\",\"\")==basic[\"doc_id\"])]\n",
    "        if len(m): row = m.iloc[0].to_dict()\n",
    "    return {**basic, **(row or {})}\n",
    "\n",
    "def load_pages(path: Path)->list[Document]:\n",
    "    # page-level documents with LangChain\n",
    "    loader = PyMuPDFLoader(str(path))\n",
    "    docs = loader.load()\n",
    "    # standardize metadata\n",
    "    did = doc_id_for(path)\n",
    "    for d in docs:\n",
    "        d.metadata.update({\n",
    "            \"doc_id\": did,\n",
    "            \"source\": str(path),\n",
    "            \"page\": d.metadata.get(\"page\", 0),\n",
    "            \"title\": d.metadata.get(\"title\") or path.stem\n",
    "        })\n",
    "        d.metadata = enrich_meta(d.metadata)\n",
    "    return docs\n",
    "\n",
    "def build_toc_coarse(path: Path, doc_id: str):\n",
    "    \"\"\"Coarse segments by TOC (chapters/sections). Fallback to 1–3 page groups.\"\"\"\n",
    "    pdf = fitz.open(path)\n",
    "    pages = len(pdf)\n",
    "    toc = pdf.get_toc(simple=True)  # [level, title, page1-based]\n",
    "    segs = []\n",
    "    if toc:\n",
    "        for i,(lvl,title,p1) in enumerate(toc):\n",
    "            p0 = max(p1-1,0)\n",
    "            p2 = (toc[i+1][2]-1) if i+1<len(toc) else pages-1\n",
    "            segs.append({\"title\":title.strip(), \"start_page\":p0, \"end_page\":p2})\n",
    "    else:\n",
    "        step = 2  # ~1–3 pages per segment\n",
    "        for p in range(0,pages,step):\n",
    "            segs.append({\"title\":f\"Section p{p+1}-{min(p+step,pages)}\",\"start_page\":p,\"end_page\":min(p+step-1,pages-1)})\n",
    "    for s in segs:\n",
    "        s[\"doc_id\"]=doc_id\n",
    "        s[\"coarse_id\"]=f\"{doc_id}:{s['start_page']}-{s['end_page']}\"\n",
    "    pdf.close()\n",
    "    return segs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b372ae03",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ModelMetaclass' from 'pydantic.main' (C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydantic\\main.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[0;32m      2\u001b[0m nlp \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men_core_web_sm\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtagger\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlemmatizer\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      3\u001b[0m nlp\u001b[38;5;241m.\u001b[39mmax_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2_000_000\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\__init__.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# set library-specific custom warning handling before doing anything else\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m setup_default_warnings\n\u001b[0;32m      8\u001b[0m setup_default_warnings()  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# These are imported as part of the API\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\errors.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Literal\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mErrorsWithCodes\u001b[39;00m(\u001b[38;5;28mtype\u001b[39m):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, code):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\compat.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Helpers for Python and platform compatibility.\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthinc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m copy_array\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcPickle\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\thinc\\__init__.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabout\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m registry\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# fmt: off\u001b[39;00m\n\u001b[0;32m      9\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregistry\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__version__\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m ]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\thinc\\config.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcatalogue\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mconfection\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config, ConfigValidationError, Promise, VARIABLE_RE\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Decorator\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\confection\\__init__.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel, create_model, ValidationError, Extra\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelMetaclass\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfields\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelField\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msrsly\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'ModelMetaclass' from 'pydantic.main' (C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydantic\\main.py)"
     ]
    }
   ],
   "source": [
    "import spacy, itertools\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\",\"tagger\",\"lemmatizer\"])\n",
    "nlp.max_length = 2_000_000\n",
    "\n",
    "def extract_ner_batch(texts: list[str])->list[dict]:\n",
    "    ents = []\n",
    "    for doc in nlp.pipe(texts, batch_size=32):\n",
    "        dd = {}\n",
    "        for e in doc.ents:\n",
    "            dd.setdefault(e.label_, set()).add(e.text)\n",
    "        ents.append({k: sorted(list(v)) for k,v in dd.items()})\n",
    "    return ents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c85a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
